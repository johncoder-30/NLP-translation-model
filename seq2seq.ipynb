{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johncoder-30/NLP-translation-model/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seq2Seq model for language translation from Tamil to English\n",
        "Seq2Seq is a method of encoder-decoder based machine translation that maps an input of sequence to an output of sequence.\n"
      ],
      "metadata": {
        "id": "8HYuIKTg7vNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Downloading of Datasets"
      ],
      "metadata": {
        "id": "Iri2noVT7-CW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Meop39CPC4XK"
      },
      "outputs": [],
      "source": [
        "# !wget https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-ta.zip\n",
        "# !unzip \"/content/en-ta.zip\" -d \"/content/data/\"\n",
        "# english_raw = open('/content/data/en-ta/train.en', 'r',encoding='utf8').read().split('\\n')\n",
        "# tamil_raw = open('/content/data/en-ta/train.ta', 'r', encoding='utf8').read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ9lZucOw68-",
        "outputId": "d64ecc10-10ac-427f-c1a9-2ba23eec3090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tamil-English-Dataset'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 39 (delta 11), reused 36 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n",
            "50001 50001\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Ishikahooda/Tamil-English-Dataset.git\n",
        "english_raw =open('/content/Tamil-English-Dataset/Dataset/data.en1', 'r',encoding='utf8').read().split('\\n')\n",
        "tamil_raw =  open('/content/Tamil-English-Dataset/Dataset/data.ta1', 'r',encoding='utf8').read().split('\\n')\n",
        "print(len(english_raw),len(tamil_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing libraries"
      ],
      "metadata": {
        "id": "mSxUcMwQ7zNY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y4Xi84fCJ5K"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing Dataset\n",
        "Converting into CSV format of english sentence and it's tamil translation"
      ],
      "metadata": {
        "id": "HkiJtSZj9mOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f_3rGxXyCWLg",
        "outputId": "7cb0d96d-1a8a-4877-d8cf-efe8d030d9f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0b196790-b941-4a7a-9e98-66432ce85a5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moreover all the vessels , which king ahaz in ...</td>\n",
              "      <td>ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>similar conditions will be imposed if the sri ...</td>\n",
              "      <td>சர்வதேச நாணய நிதியம் இலங்கைக்கு கடன் வழங்கினால...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>now kornelius argues the opposite instead of e...</td>\n",
              "      <td>தற்போது அதற்கு எதிராக வாதாடுகிறார் சர்வதேச சட...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chrysler the third largest us automaker filed ...</td>\n",
              "      <td>அமெரிக்காவின் மூன்றாம் பெரிய கார் தயாரிப்பு நி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moreover , khan has been in exile in iran for ...</td>\n",
              "      <td>மேலும் இனைவிட்டு தலிபானால் வெளியேற்றப்பட்ட 199...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b196790-b941-4a7a-9e98-66432ce85a5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b196790-b941-4a7a-9e98-66432ce85a5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b196790-b941-4a7a-9e98-66432ce85a5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             English                                              Tamil\n",
              "0  moreover all the vessels , which king ahaz in ...  ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தி...\n",
              "1  similar conditions will be imposed if the sri ...  சர்வதேச நாணய நிதியம் இலங்கைக்கு கடன் வழங்கினால...\n",
              "2  now kornelius argues the opposite instead of e...  தற்போது அதற்கு எதிராக வாதாடுகிறார் சர்வதேச சட...\n",
              "3  chrysler the third largest us automaker filed ...  அமெரிக்காவின் மூன்றாம் பெரிய கார் தயாரிப்பு நி...\n",
              "4  moreover , khan has been in exile in iran for ...  மேலும் இனைவிட்டு தலிபானால் வெளியேற்றப்பட்ட 199..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "# print(english_raw[10],tamil_raw[10])\n",
        "raw_data = {'English': [line for line in english_raw[:1000]],\n",
        "            'Tamil': [line for line in tamil_raw[:1000]]}\n",
        "df = pd.DataFrame(raw_data, columns=['English', 'Tamil'])\n",
        "train, test = train_test_split(df, test_size=0.05,shuffle=False)\n",
        "train.to_csv('train.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "517-LOAbCWWi",
        "outputId": "906eb698-9772-4626-c225-ff53051204c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'says', 'she', 'knows', 'what', 'is', 'going', 'on', 'but', 'can', 'do', 'nothing', 'about', 'it']\n",
            "['என்ன', 'நடக்கிறது', 'என்பது', 'தமக்கு', 'தெரியும்', 'என்றும்', 'ஆனால்,', 'தம்மால்', 'எதுவும்', 'செய்யமுடியாது', 'என்றும்', 'கடிதம்', 'எழுதியிருந்தார்.']\n"
          ]
        }
      ],
      "source": [
        "# spacy_eng = spacy.load('en_core_web_sm')\n",
        "def tokenize_eng(sentence):\n",
        "    sentence = re.sub(r'\\n', '', sentence)\n",
        "    sentence = re.sub(r'[^\\w\\s\\']', '', sentence.lower())\n",
        "    return [words for words in sentence.split()]\n",
        "# print(tokenize_eng('Every tournament is difficult.'))\n",
        "print(tokenize_eng('She says she knows what is going on, but can do nothing about it.'))\n",
        "\n",
        "def tokenize_tam(sentence):\n",
        "    sentence = re.sub(r'\\n', '', sentence)\n",
        "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)\n",
        "    sentence = re.sub(r'\\'\\\"\\.','',sentence)\n",
        "    return [words for words in sentence.split()]\n",
        "# print(tokenize_tam('ஒவ்வொரு சுற்றுப்பயணமும் கடினமானது.'))\n",
        "print(tokenize_tam('என்ன நடக்கிறது என்பது தமக்கு தெரியும் என்றும் ஆனால், தம்மால் எதுவும் செய்யமுடியாது என்றும் கடிதம் எழுதியிருந்தார்.'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using torchtext library to\n",
        ">1. tokenize sentences,\n",
        ">2. build vocabulary \n",
        ">3. splitting into batches to train in GPU"
      ],
      "metadata": {
        "id": "jblqmRbH98-t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw_7dwNYCWcr"
      },
      "outputs": [],
      "source": [
        "english = Field(init_token='<sos>',eos_token='<eos>', tokenize=tokenize_eng, lower=True,batch_first=True)\n",
        "tamil = Field(init_token='<sos>',eos_token='<eos>', tokenize=tokenize_tam, lower=False,batch_first=True)\n",
        "fields = {'English': ('eng', english), 'Tamil': ('tam', tamil)}\n",
        "train_data, test_data = TabularDataset.splits(path='', train='train.csv', test='test.csv', format='csv', fields=fields)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "tamil.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data),\n",
        "                    batch_size=32, device='cuda',sort_key = lambda x: len(x.tam),sort_within_batch=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder "
      ],
      "metadata": {
        "id": "Lh1kgs73_LZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cvihpbLCWm7"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):  # input->Tamil sentences\n",
        "    def __init__(self, input_size, hidden_dim, embedding_size, num_layers, p):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_dim, num_layers=num_layers, dropout=p, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape -> (N,seq_len)\n",
        "        out = self.dropout(self.embedding(x))\n",
        "        batch_size = x.shape[0]\n",
        "        # x shape -> (N,seq_len,embedding_shape)\n",
        "        hid = torch.zeros(self.num_layers, batch_size, self.hidden_size).to('cuda')\n",
        "        cel = torch.zeros(self.num_layers, batch_size, self.hidden_size).to('cuda')\n",
        "        output, (hidden, cell) = self.lstm(out, (hid, cel))\n",
        "        # output shape -> (N,L,hid_dim)\n",
        "        # hidden shape -> (num_layers,N,Hid_dim)\n",
        "        return hidden, cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "LlkLVZAo_oZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNF_O1CuCWsK"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_dim, output_size, num_layers, p):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_dim, num_layers, dropout=p, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        x = x.unsqueeze(1)\n",
        "        out = self.dropout(self.embedding(x))\n",
        "        output, (hidden, cell) = self.lstm(out, (hidden, cell))\n",
        "        prediction = self.linear(output.squeeze(1))\n",
        "        return prediction, hidden, cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seq2Seq"
      ],
      "metadata": {
        "id": "78PYX8ZS_qUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0vsSteRyuFH"
      },
      "outputs": [],
      "source": [
        "class Seq2seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_force_ratio=0.6):\n",
        "        batch_size = src.shape[0]\n",
        "        target_len = trg.shape[1]\n",
        "        target_vocab_size = len(english.vocab)\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
        "        hidden, cell = self.encoder(src)\n",
        "        x = trg[:, 0]\n",
        "        for i in range(1, target_len):\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "            outputs[:, i, :] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            x = trg[:, i] if random.random() < teacher_force_ratio else best_guess\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters for model "
      ],
      "metadata": {
        "id": "5paNMg9t_uNY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoAJ8Lk0yuOw",
        "outputId": "6b0627c9-9af7-4d53-b93c-c41c3a4ae9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1665 1845\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "num_epochs = 175\n",
        "learning_rate = 0.003\n",
        "device = torch.device('cuda')\n",
        "input_size_encoder = len(tamil.vocab)\n",
        "input_size_decoder = len(english.vocab)\n",
        "output_size = len(english.vocab)\n",
        "encoder_embedding_size = 256\n",
        "decoder_embedding_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5\n",
        "batch_size = 32\n",
        "print(input_size_encoder,input_size_decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IKECkovyuVD"
      },
      "outputs": [],
      "source": [
        "encoder_net = Encoder(input_size=input_size_encoder, embedding_size=encoder_embedding_size, hidden_dim=hidden_size,\n",
        "                      num_layers=num_layers, p=enc_dropout).to('cuda')\n",
        "decoder_net = Decoder(input_size=input_size_decoder, embedding_size=decoder_embedding_size, hidden_dim=hidden_size,\n",
        "                      output_size=output_size, num_layers=num_layers, p=dec_dropout).to('cuda')\n",
        "model = Seq2seq(encoder_net, decoder_net, device).to(device)\n",
        "pad_idx = english.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test function to check model output while training"
      ],
      "metadata": {
        "id": "EEF2syTD_7e8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T60kiAhFFAKp"
      },
      "outputs": [],
      "source": [
        "# def eng_decoder(sentence):\n",
        "#     dec = []\n",
        "#     for idx in sentence:\n",
        "#         if (int(idx) in eng_idx2word) and int(idx) != 0:\n",
        "#             dec.append(eng_idx2word[int(idx)])\n",
        "#     return dec\n",
        "def test_model():\n",
        "    model.eval()\n",
        "    # tam_sen = '<sos> இதனால் மக்களின் இயல்பு வாழ்க்கை பெரிதும் பாதிப்படைந்துள்ளது. <eos>' \n",
        "    tam_sen = '<sos> என்ன நடக்கிறது என்பது தமக்கு தெரியும் என்றும் ஆனால், தம்மால் எதுவும் செய்யமுடியாது என்றும் கடிதம் எழுதியிருந்தார். <eos>'   \n",
        "    tam_encoded=[]\n",
        "    for x in tokenize_tam(tam_sen):\n",
        "        tam_encoded.append(tamil.vocab.stoi[x])\n",
        "    tam_sen = torch.Tensor(tam_encoded).long().to('cuda')\n",
        "    tam_sen = tam_sen.reshape(1,-1)\n",
        "    \n",
        "    # eng_sen = '<sos> This has made the life of people very miserable. <eos>'\n",
        "    eng_sen = '<sos> She says she knows what is going on, but can do nothing about it. <eos>'\n",
        "    eng_encoded=[]\n",
        "    for x in tokenize_eng(eng_sen):\n",
        "        eng_encoded.append(english.vocab.stoi[x])\n",
        "    eng_sen = torch.Tensor(eng_encoded).long().to('cuda')\n",
        "    eng_sen = eng_sen.reshape(1,-1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(tam_sen, eng_sen, 0)\n",
        "        out = out.reshape(-1, out.shape[2])\n",
        "        out = out.argmax(1)\n",
        "        # out_sen = eng_decoder(out)\n",
        "        for a in out:\n",
        "            if int(a)!=pad_idx:\n",
        "                print(english.vocab.itos[int(a)],end=' ')\n",
        "        print('\\n')\n",
        "# test_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Seq2seq model"
      ],
      "metadata": {
        "id": "QoOvev_6AG5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9O8gVVryubV",
        "outputId": "79804a5b-8018-49ee-e884-9ad37a2c6da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5 loss: 5.149782180786133\n",
            "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <eos> <eos> <eos> \n",
            "\n",
            "epoch: 10 loss: 3.724816083908081\n",
            "<unk> the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <eos> <eos> <eos> <eos> \n",
            "\n",
            "epoch: 15 loss: 4.5774030685424805\n",
            "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <eos> <unk> <eos> <eos> \n",
            "\n",
            "epoch: 20 loss: 3.644441604614258\n",
            "<unk> the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <eos> <eos> <eos> \n",
            "\n",
            "epoch: 25 loss: 4.279374122619629\n",
            "<unk> i 'm <unk> <unk> <unk> <unk> <unk> and <unk> and <unk> <unk> <eos> <eos> <eos> \n",
            "\n",
            "epoch: 30 loss: 4.296356678009033\n",
            "<unk> i have done judgment and justice leave the <unk> of the lord there was none \n",
            "\n",
            "epoch: 35 loss: 3.81123685836792\n",
            "<unk> i 'm looking for the sources of information and the <unk> because he might <unk> \n",
            "\n",
            "epoch: 40 loss: 3.011389970779419\n",
            "<unk> i fell to pay for the area and <unk> <unk> <unk> to <unk> <eos> <eos> \n",
            "\n",
            "epoch: 45 loss: 1.4832310676574707\n",
            "<unk> i 'm sure what he thought he saw was so much he was <eos> <eos> \n",
            "\n",
            "epoch: 50 loss: 3.016791343688965\n",
            "<unk> i 'm looking for <unk> a thriller servant and <unk> <unk> <unk> <eos> <eos> <eos> \n",
            "\n",
            "epoch: 55 loss: 2.5161654949188232\n",
            "<unk> you don 't know what he thought he saw was <unk> our <unk> <eos> <eos> \n",
            "\n",
            "epoch: 60 loss: 0.934134304523468\n",
            "<unk> <unk> don 't know what you 're <unk> into you <unk> pocket <eos> <eos> <eos> \n",
            "\n",
            "epoch: 65 loss: 1.7682888507843018\n",
            "<unk> we don 't feel <unk> facilities the <unk> management <unk> them <eos> statutes <eos> <eos> \n",
            "\n",
            "epoch: 70 loss: 1.4794862270355225\n",
            "<unk> my sheep hear my voice and i know them and they <unk> me <eos> boy \n",
            "\n",
            "epoch: 75 loss: 1.439664363861084\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 80 loss: 2.819242477416992\n",
            "<unk> she says she knows what and asked for a car to <unk> australia <eos> <unk> \n",
            "\n",
            "epoch: 85 loss: 1.6825289726257324\n",
            "<unk> she says she knows what is going on <unk> <unk> <unk> <eos> <eos> <eos> <eos> \n",
            "\n",
            "epoch: 90 loss: 2.0033421516418457\n",
            "<unk> she says she knows what and asked out who <unk> it again <eos> <eos> <eos> \n",
            "\n",
            "epoch: 95 loss: 0.17466509342193604\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 100 loss: 1.9358974695205688\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 105 loss: 1.4089932441711426\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 110 loss: 0.9487301707267761\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 115 loss: 0.1147049218416214\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 120 loss: 0.5890336036682129\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 125 loss: 0.07601230591535568\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 130 loss: 0.9980000853538513\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 135 loss: 0.28087154030799866\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 140 loss: 0.2779838740825653\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 145 loss: 0.04660891368985176\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 150 loss: 0.20558366179466248\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 155 loss: 0.51047283411026\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 160 loss: 0.24142774939537048\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 165 loss: 0.554158627986908\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 170 loss: 0.05516685172915459\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n",
            "epoch: 175 loss: 0.17130166292190552\n",
            "<unk> she says she knows what is going on but can do nothing about it <eos> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1,num_epochs+1):\n",
        "    model.train()\n",
        "    for i, batch in enumerate(train_iterator):\n",
        "        src, tar = batch.tam.to(device), batch.eng.to(device)\n",
        "        # print(src.shape,tar.shape)\n",
        "        out = model(src, tar)\n",
        "        out = out[:,1:,:].reshape(-1, out.shape[2])\n",
        "        tar = tar[:,1:].reshape(-1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(out, tar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch%5==0:\n",
        "        print('epoch:', epoch, 'loss:', loss.item())\n",
        "        test_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To save trained-model to google drive"
      ],
      "metadata": {
        "id": "sjpCVn9sAWVI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vfGWtFarlYZN",
        "outputId": "fb1e38cf-e6b5-4b3b-e76f-eb54d2ac6f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "seq2seq_model.pt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls '/content/gdrive/My Drive/pytorch_models'\n",
        "\n",
        "#save model\n",
        "model_save_name = 'seq2seq_model.pt'\n",
        "path = F\"/content/gdrive/My Drive/pytorch_models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)\n",
        "torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss.item(),\n",
        "                }, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To load saved model from google drive "
      ],
      "metadata": {
        "id": "iOcKrbTxAdlX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJngoe13leSI",
        "outputId": "753caa80-8b88-494e-84af-d679cdce873f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(1648, 256)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(1849, 256)\n",
              "    (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "    (linear): Linear(in_features=512, out_features=1849, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load model from g_drive\n",
        "model = Seq2seq(encoder_net, decoder_net, device).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model_save_name = 'seq2seq_model.pt'\n",
        "path = F\"/content/gdrive/My Drive/pytorch_models/{model_save_name}\"\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "seq2seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKhWs09eERUJZeWOof6rM1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}