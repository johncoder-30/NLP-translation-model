{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johncoder-30/NLP-translation-model/blob/main/transformer_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer based model to translate tamil sentences to english\n",
        "A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data. It is used primarily in the field of natural language processing (NLP) and in computer vision (CV)."
      ],
      "metadata": {
        "id": "U-UrVB2Z6O8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloading of Datasets"
      ],
      "metadata": {
        "id": "3KUsQTA07WHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0SNYcsvpslL",
        "outputId": "07baf962-c333-4eb1-eb09-50f56b0b4766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-03 09:15:47--  https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-ta.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 173.194.217.128, 173.194.218.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1377236241 (1.3G) [application/zip]\n",
            "Saving to: ‘en-ta.zip’\n",
            "\n",
            "en-ta.zip           100%[===================>]   1.28G   103MB/s    in 10s     \n",
            "\n",
            "2022-02-03 09:15:57 (129 MB/s) - ‘en-ta.zip’ saved [1377236241/1377236241]\n",
            "\n",
            "Archive:  /content/en-ta.zip\n",
            "   creating: /content/data/en-ta/\n",
            " extracting: /content/data/en-ta/train.ta  \n",
            " extracting: /content/data/en-ta/train.en  \n",
            "5095764 5095764\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-ta.zip\n",
        "!unzip \"/content/en-ta.zip\" -d \"/content/data/\"\n",
        "english_raw = open('/content/data/en-ta/train.en', 'r',encoding='utf8').read().split('\\n')\n",
        "tamil_raw = open('/content/data/en-ta/train.ta', 'r', encoding='utf8').read().split('\\n')\n",
        "\n",
        "print(len(english_raw), len(tamil_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing libraries"
      ],
      "metadata": {
        "id": "kQudsUny7eGd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iTp0Ptw1oZ8p"
      },
      "outputs": [],
      "source": [
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing Dataset"
      ],
      "metadata": {
        "id": "JX7gsH3J7qb2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "xEeqNBEkoaDw",
        "outputId": "692a07d5-9689-40f9-b8e1-992aba7a8edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19991, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1c968be-29ed-445c-a664-69df89f81d64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>That's what I am saying.</td>\n",
              "      <td>என்றுதான் நான் சொல்ல வருகிறேன்.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Every tournament is difficult.</td>\n",
              "      <td>ஒவ்வொரு சுற்றுப்பயணமும் கடினமானது.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One of the first questions Flavio posed was, D...</td>\n",
              "      <td>பல வருடங்களாக அவர் அந்த நித்திய எரிநரக தண்டனைய...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>He gave full credit to the Union Finance Minis...</td>\n",
              "      <td>அவர் நிதி அமைச்சர் அருண்ஜேட்லியின் முயற்சியை த...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Some art historians have suggested that he onl...</td>\n",
              "      <td>சில கலை வரலாற்றாசிரியர்கள் அவர் ஒரு வருடத்திற்...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>Events in the Balkans led to the outbreak of W...</td>\n",
              "      <td>ஏனெனில் 1914 ஜூலையில்சேர்பியாவுக்கு ஆஸ்திரியா ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>That is very important and should not be omitted.</td>\n",
              "      <td>இது மிக முக்கியமான ஒன்றாகும், மேலும் இதை தாமதப...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>Food and water</td>\n",
              "      <td>தண்ணீரும் பாலும்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>For many decades the extreme wealth in India w...</td>\n",
              "      <td>பல தசாப்தங்களாக இந்தியாவில் வளம் டாடாக்கள் மற்...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>' he said.</td>\n",
              "      <td>'' என்று கூறி சென்றது.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19991 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1c968be-29ed-445c-a664-69df89f81d64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1c968be-29ed-445c-a664-69df89f81d64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1c968be-29ed-445c-a664-69df89f81d64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 English                                              Tamil\n",
              "0                               That's what I am saying.                    என்றுதான் நான் சொல்ல வருகிறேன்.\n",
              "1                         Every tournament is difficult.                 ஒவ்வொரு சுற்றுப்பயணமும் கடினமானது.\n",
              "2      One of the first questions Flavio posed was, D...  பல வருடங்களாக அவர் அந்த நித்திய எரிநரக தண்டனைய...\n",
              "3      He gave full credit to the Union Finance Minis...  அவர் நிதி அமைச்சர் அருண்ஜேட்லியின் முயற்சியை த...\n",
              "4      Some art historians have suggested that he onl...  சில கலை வரலாற்றாசிரியர்கள் அவர் ஒரு வருடத்திற்...\n",
              "...                                                  ...                                                ...\n",
              "19995  Events in the Balkans led to the outbreak of W...  ஏனெனில் 1914 ஜூலையில்சேர்பியாவுக்கு ஆஸ்திரியா ...\n",
              "19996  That is very important and should not be omitted.  இது மிக முக்கியமான ஒன்றாகும், மேலும் இதை தாமதப...\n",
              "19997                                     Food and water                                   தண்ணீரும் பாலும்\n",
              "19998  For many decades the extreme wealth in India w...  பல தசாப்தங்களாக இந்தியாவில் வளம் டாடாக்கள் மற்...\n",
              "19999                                         ' he said.                             '' என்று கூறி சென்றது.\n",
              "\n",
              "[19991 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# print(english_raw[10],tamil_raw[10])\n",
        "raw_data = {'English': [line for line in english_raw[:20000]],\n",
        "            'Tamil': [line for line in tamil_raw[:20000]]}\n",
        "df = pd.DataFrame(raw_data, columns=['English', 'Tamil'])\n",
        "df=df[df['English'].str.split(' ').map(len) < 100]\n",
        "df=df[df['Tamil'].str.split(' ').map(len) < 100]\n",
        "train, test = train_test_split(df, test_size=0.05,random_state=1234)\n",
        "train.to_csv('train.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)\n",
        "print(df.shape)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fwsyVwZoaK-",
        "outputId": "6e9e7238-fb17-4cac-b2d1-665cf6a36242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'says', 'she', 'knows', 'what', 'is', 'going', 'on', 'but', 'can', 'do', 'nothing', 'about', 'it']\n",
            "['என்ன', 'நடக்கிறது', 'என்பது', 'தமக்கு', 'தெரியும்', 'என்றும்', 'ஆனால்', 'தம்மால்', 'எதுவும்', 'செய்யமுடியாது', 'என்றும்', 'கடிதம்', 'எழுதியிருந்தார்']\n"
          ]
        }
      ],
      "source": [
        "def tokenize_eng(sentence):\n",
        "    sentence = re.sub(r'\\n', '', sentence)\n",
        "    # sentence = re.sub(r'[^\\w\\s\\']', '', sentence.lower())\n",
        "    sentence = re.sub(r'[\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]', '', sentence.lower())\n",
        "    return [words for words in sentence.split()]\n",
        "\n",
        "print(tokenize_eng('She says she knows what is going on, but can do nothing about it.'))\n",
        "\n",
        "def tokenize_tam(sentence):\n",
        "    sentence = re.sub(r'\\n', '', sentence)\n",
        "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)\n",
        "    sentence = re.sub(r'[\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]', '', sentence)\n",
        "    return [words for words in sentence.split()]\n",
        "\n",
        "print(tokenize_tam('என்ன நடக்கிறது என்பது தமக்கு தெரியும் என்றும் ஆனால், தம்மால் எதுவும் செய்யமுடியாது என்றும் கடிதம் எழுதியிருந்தார்.'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using torchtext library to\n",
        ">1. tokenize sentences,\n",
        ">2. build vocabulary \n",
        ">3. splitting into batches to train in GPU"
      ],
      "metadata": {
        "id": "OhExaX8L75Jr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8k0tgGfGoaRF"
      },
      "outputs": [],
      "source": [
        "english = Field(init_token='<sos>', eos_token='<eos>', tokenize=tokenize_eng, lower=True, batch_first=False)\n",
        "tamil = Field(init_token='<sos>', eos_token='<eos>', tokenize=tokenize_tam, lower=False, batch_first=False)\n",
        "fields = {'English': ('eng', english), 'Tamil': ('tam', tamil)}\n",
        "train_data, test_data = TabularDataset.splits(path='', train='train.csv', test='test.csv', format='csv', fields=fields)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "tamil.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data),\n",
        "                                                      batch_size=128, device='cuda', sort_key=lambda x: len(x.tam),\n",
        "                                                      sort_within_batch=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer Model"
      ],
      "metadata": {
        "id": "xaEHpyWI7-I0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8rv7jICcoaYL"
      },
      "outputs": [],
      "source": [
        "class Transformer_model(nn.Module):\n",
        "    def __init__(self, embedding_size, src_vocab_size, trg_vocab_size, src_pad_idx, num_heads, num_encoder_layers,\n",
        "                 num_decoder_layers, feed_forward, dropout_p, max_len, device):\n",
        "        super(Transformer_model, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(embedding_size, num_heads, num_encoder_layers,num_decoder_layers, feed_forward, dropout_p)\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        # src_shape=(src_len,N)\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "        # src_shape=(N,src_len)\n",
        "        return src_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_length, N = src.shape\n",
        "        trg_seq_length, N = trg.shape\n",
        "\n",
        "        src_positions = (torch.arange(0, src_seq_length).unsqueeze(1).expand(src_seq_length, N).to(self.device))\n",
        "        trg_positions = (torch.arange(0, trg_seq_length).unsqueeze(1).expand(trg_seq_length, N).to(self.device))\n",
        "\n",
        "        embed_src = self.dropout(self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        embed_trg = self.dropout(self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src).to(self.device)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(self.device)\n",
        "\n",
        "        out = self.transformer(embed_src, embed_trg, src_key_padding_mask=src_padding_mask, tgt_mask=trg_mask)\n",
        "        out = self.fc_out(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameters for Model"
      ],
      "metadata": {
        "id": "1htp3Nhk8E2e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JSmn91MoafY",
        "outputId": "6951f514-5054-4e37-b1c3-a25b5113c864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10004 9862\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "num_epoch = 100\n",
        "learning_rate = 3e-4\n",
        "batch_size = 128\n",
        "\n",
        "src_vocab_size = len(tamil.vocab)\n",
        "trg_vocab_size = len(english.vocab)\n",
        "print(src_vocab_size,trg_vocab_size)\n",
        "embedding_size = 512\n",
        "num_heads = 4\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 100\n",
        "feed_forward = 2048\n",
        "src_pad_idx = tamil.vocab.stoi['<pad>']\n",
        "\n",
        "model = Transformer_model(embedding_size, src_vocab_size, trg_vocab_size, src_pad_idx, num_heads, num_encoder_layers, num_decoder_layers, feed_forward,dropout, max_len, device).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "pad_idx = english.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading pre trained Model"
      ],
      "metadata": {
        "id": "046ZJ1YV8LuW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gRCw9uq2oa7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cc820b-1dea-48ec-aafd-195ee24132c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "do you want to load model:yes\n",
            "Mounted at /content/gdrive\n",
            "seq2seq_attention.pt  seq2seq_transformer_200.pt\n"
          ]
        }
      ],
      "source": [
        "# # load model from g_drive\n",
        "# model = Transformer_model(embedding_size, src_vocab_size, trg_vocab_size, src_pad_idx, num_heads, num_encoder_layers, num_decoder_layers, feed_forward,dropout, max_len, device).to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "q=input('do you want to load model:')\n",
        "if q=='yes':\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/gdrive')\n",
        "    !ls '/content/gdrive/My Drive/pytorch_models'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q=input('Do u want to continue :')\n",
        "if q=='yes':\n",
        "    model_save_name = 'seq2seq_transformer_200.pt'\n",
        "    path = F\"/content/gdrive/My Drive/pytorch_models/{model_save_name}\"\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "\n",
        "    # model.eval()\n",
        "    # - or -\n",
        "    model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rrsDsnQ0cKW",
        "outputId": "3a8dce64-aa7f-46d4-8f91-07e4c73f40de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do u want to continue :yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test function to check model output while training"
      ],
      "metadata": {
        "id": "-b3jFT6u8VGG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cyalqIoPoal3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843ecaea-d66a-4e78-fa6e-450766fc0457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> people from nearby villages also came to watch the celebrations <eos> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def test_model():\n",
        "    model.eval()\n",
        "    tam_sen = '<sos> திருவிழாவைக் காண அருகில் இருக்கும் கிராமங் களைச் சேர்ந்தவர்கள் மறவப்பட் டிக்கு படையெடுத்துவந்தனர். <eos>'\n",
        "    # tam_sen = '<sos> கடந்த 5 ஆண்டுகளில் பயனடைந்தோர் மற்றும் செலவின விவரம் பின்வருமாறு <eos>'\n",
        "    # tam_sen = '<sos> இது காட்டிற்கு செல்லும் வழி <eos>'\n",
        "    # tam_sen = '<sos> சில கலை வரலாற்றாசிரியர்கள் அவர் ஒரு வருடத்திற்கு இரண்டு அல்லது மூன்று ஓவியங்களை மட்டுமே தயாரித்துள்ளதாக தெரிவித்திருக்கிறார்கள். <eos>'\n",
        "    tam_encoded = []\n",
        "    for x in tokenize_tam(tam_sen):\n",
        "        tam_encoded.append(tamil.vocab.stoi[x])\n",
        "    tam_sen = torch.Tensor(tam_encoded).long().to(device)\n",
        "    tam_sen = tam_sen.reshape(-1, 1)\n",
        "    \n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for i in range(100):\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(tam_sen, trg_tensor)\n",
        "\n",
        "        best_guess = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    for a in translated_sentence:\n",
        "            print(a, end=' ')\n",
        "    print('\\n')\n",
        "test_model()\n",
        "\n",
        "def eng_decoder(sen):\n",
        "    for a in sen:\n",
        "        for b in a:\n",
        "            print(english.vocab.itos[int(b)], end=' ')\n",
        "        print()\n",
        "\n",
        "def save_model():\n",
        "    model_save_name = 'seq2seq_transformer.pt'\n",
        "    path = F\"/content/{model_save_name}\"\n",
        "# torch.save(model.state_dict(), path)\n",
        "    torch.save({\n",
        "    'epoch': _epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss.item(),\n",
        "        }, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Transformer Model"
      ],
      "metadata": {
        "id": "8FNP2WsL8hHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHFCJunsoatW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a1c562-8f4a-4b55-9d62-a1cf7a4d9e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 100  loss= 0.33221444487571716\n",
            "<sos> the number of 65 students have participated in the programme <eos> \n",
            "\n",
            "epoch: 105  loss= 0.709135115146637\n",
            "<sos> besides youths in large numbers participated in <unk> <eos> \n",
            "\n",
            "epoch: 110  loss= 0.5519265532493591\n",
            "<sos> the phone has a <unk> <unk> front camera <eos> \n",
            "\n",
            "epoch: 115  loss= 0.3861539959907532\n",
            "<sos> besides parents and students were also present <eos> \n",
            "\n",
            "epoch: 120  loss= 0.391206294298172\n",
            "<sos> details of sanctioned students admission strength for the year 201415 at tanuvas are furnished below <eos> \n",
            "\n",
            "epoch: 125  loss= 0.34915032982826233\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 130  loss= 0.3442474603652954\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 135  loss= 0.2777898907661438\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 140  loss= 0.6602615714073181\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 145  loss= 0.322653591632843\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 150  loss= 0.2491031289100647\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 155  loss= 0.2964872121810913\n",
            "<sos> last year nearly 100 people were killed in a series of bomb attacks at <unk> functions public meetings a mosque and a church <eos> \n",
            "\n",
            "epoch: 160  loss= 0.24147963523864746\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 165  loss= 0.2131580412387848\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 170  loss= 0.25167223811149597\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 175  loss= 0.21182918548583984\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 180  loss= 0.2112819403409958\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 185  loss= 0.1838187724351883\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 190  loss= 0.3001422584056854\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n",
            "epoch: 195  loss= 0.15885572135448456\n",
            "<sos> details of beneficiaries and expenditure incurred during the last 5 years are <eos> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _epoch in range(epoch,epoch+100):\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        inp_data = batch.tam.to(device)\n",
        "        target = batch.eng.to(device)\n",
        "        # eng_decoder(target)\n",
        "        # print(target.shape,inp_data.shape)\n",
        "\n",
        "        output = model(inp_data, target[:-1,:])\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        \n",
        "    if epoch%5==0:\n",
        "        print('epoch:',_epoch,' loss=',loss.item())\n",
        "        test_model()\n",
        "        save_model()\n",
        "        model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save Model"
      ],
      "metadata": {
        "id": "gTiledC58noM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WSYAWzyWEcS"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "model_save_name = 'seq2seq_transformer_200.pt'\n",
        "path = F\"/content/gdrive/My Drive/pytorch_models/{model_save_name}\"\n",
        "# torch.save(model.state_dict(), path)\n",
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss.item(),\n",
        "}, path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "transformer_translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9KtLq1B/39wi2Sy1nWspS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}